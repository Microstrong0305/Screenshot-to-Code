# 总结自己在使用Keras中遇到的各种问题
1. [神经网络中concatenate和add层的不同](https://blog.csdn.net/u012193416/article/details/79479935)
2. [理解LSTM在keras API中参数return_sequences和return_state](https://blog.csdn.net/qq_25439417/article/details/83539284)
	+ [理解LSTM在keras API中参数return_sequences和return_state](https://blog.csdn.net/u011327333/article/details/78501054/)
3. [attention map注意力可视化 feature map可视化](https://blog.csdn.net/u013608336/article/details/82792871)
4. Keras中实现注意力机制
	- [Keras实现注意力机制](https://blog.csdn.net/uhauha2929/article/details/80733255)
	- [Attention_Network_With_Keras](https://muffintech.org/blog/id/12/) | [GitHub](https://github.com/Choco31415/Attention_Network_With_Keras)
	- [keras实现Attention机制](https://www.jianshu.com/p/31c0acf94e0e)
	- [keras for attention](https://blog.csdn.net/u010041824/article/details/78855435)


# paper中用到的开源库
1. [Keras Attention Mechanism](https://github.com/philipperemy/keras-attention-mechanism)

